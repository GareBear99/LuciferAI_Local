# ğŸ§ª Manual Testing Guide for LuciferAI

This guide covers commands that require manual interaction and cannot be fully automated.

---

## âœ… Test 1: DELETE Command with Trash Confirmation

### Setup
```bash
echo "test file" > ~/Desktop/test_delete.txt
```

### Command
```
delete the file test_delete.txt on my desktop
```

### Expected Behavior
1. âœ“ Finds the file at `~/Desktop/test_delete.txt`
2. âœ“ Shows: `Found: /Users/[user]/Desktop/test_delete.txt`
3. âœ“ Prompts: `Move to trash? (y/n):`
4. âœ“ If `y`: File moves to macOS Trash (via `osascript`)
5. âœ“ If `n`: Operation cancelled
6. âœ“ File no longer exists at original location

### Verify
```bash
# Check file is gone
ls ~/Desktop/test_delete.txt  # Should not exist

# Check Trash
open ~/.Trash  # Should see test_delete.txt
```

---

## âœ… Test 2: OPEN Command with App Selection

### Setup
```bash
echo "# Test README" > ~/Desktop/test_readme.md
```

### Command
```
open test_readme.md
```

### Expected Behavior
1. âœ“ Finds file (if multiple, shows numbered list)
2. âœ“ If multiple matches:
   - Shows: `Multiple files found:`
   - Lists files with numbers
   - Prompts: `Select file (1-N or 0 to cancel):`
   - Shows selected path
   - Prompts: `Is this correct? (y/n):`
   - If `n`: Shows list again
3. âœ“ Once confirmed, shows app options:
   ```
   Available apps:
   1. vscode
   2. sublime
   3. system default
   Select app (1-3 or 0):
   ```
4. âœ“ Opens file with selected app
5. âœ“ If wrong app selected: `Would you like to try again? (y/n)`

### Verify
- File opens in the selected application

---

## âœ… Test 3: DAEMON WATCH (No Autofix)

### Setup
```bash
cat > ~/Desktop/test_watch.py << 'EOF'
import sys

def calculate(x, y):
    result = x / y  # Potential ZeroDivisionError
    return result

print(calculate(10, 0))
EOF
```

### Command
```
daemon watch test_watch.py
```

### Expected Behavior
1. âœ“ Finds script (multi-select if multiple matches)
2. âœ“ Shows path with confirmation: `Watch this file? (y/n):`
3. âœ“ Prompts: `Enable autofix mode? (y/n):`
4. âœ“ If `n` (no autofix):
   - Watches file for changes
   - When error detected, shows:
     ```
     ğŸ” Top 3 Consensus Fixes:
     
     [1] Score: 95.0% | Success: 42/45
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Add zero division check               â”‚
     â”‚  if y == 0: raise ValueError("zero")   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     
     [2] Score: 87.0% | Success: 38/45
     ...
     ```
   - **White background** for fix suggestions
   - Does NOT auto-apply
   - Continues watching

### Verify
```bash
# Trigger error by modifying file
echo "# comment" >> ~/Desktop/test_watch.py

# Should see consensus fixes displayed
```

---

## âœ… Test 4: DAEMON WATCH (With Autofix)

### Command
```
daemon watch test_watch.py
```

### Expected Behavior (Select `y` for autofix)
1. âœ“ Same initial steps as Test 3
2. âœ“ When error detected:
   - Shows: `ğŸ”§ Applying best fix...`
   - Automatically applies highest-scored consensus fix
   - Shows: `âœ“ Fix applied and verified`
   - Continues watching with fix in place

### Verify
```bash
cat ~/Desktop/test_watch.py
# Should see zero-division check added
```

---

## âœ… Test 5: FIX SCRIPT Command

### Setup
Use the test file from conversation:
```bash
cat > ~/Desktop/test_fix.py << 'EOF'
import sys
import os

def process_data():
    data = json.dumps({"test": "value", "number": 42})  # Missing json import
    return data

if __name__ == "__main__":
    print(process_data())
EOF
```

### Command
```
fix ~/Desktop/test_fix.py
```

### Expected Behavior
1. âœ“ Detects error: `NameError: name 'json' is not defined`
2. âœ“ Searches consensus dictionary for matching error
3. âœ“ Shows: `Searching consensus for: NameError: name 'json' is not defined`
4. âœ“ Finds fix: `Add: import json`
5. âœ“ Applies fix to file
6. âœ“ Verifies: Runs script to confirm it works
7. âœ“ Shows: `âœ“ Fix verified - script runs successfully`

### Verify
```bash
python3 ~/Desktop/test_fix.py
# Should output: {"test": "value", "number": 42}

head -3 ~/Desktop/test_fix.py
# Should show: import json added at top
```

---

## âœ… Test 6: COMMAND HISTORY (Up/Down Arrows)

### Test A: Within Session
1. Run: `help`
2. Run: `pwd`
3. Run: `memory`
4. Press **Up Arrow** â†’ Should show `memory`
5. Press **Up Arrow** â†’ Should show `pwd`
6. Press **Up Arrow** â†’ Should show `help`
7. Press **Down Arrow** â†’ Should show `pwd`
8. Press **Enter** â†’ Runs `pwd`

### Test B: Across Restarts
1. Run several commands (e.g., `help`, `list ~`, `pwd`)
2. Exit LuciferAI: `exit`
3. Restart LuciferAI: `python3 lucifer.py`
4. Press **Up Arrow** immediately
5. âœ“ Should show last command from previous session
6. âœ“ Can navigate through last 120 commands

### Verify
```bash
cat ~/.luciferai/data/command_history.txt
# Should contain last 120 commands
wc -l ~/.luciferai/data/command_history.txt
# Should be â‰¤ 120 lines
```

---

## âœ… Test 7: MULTI-FILE SELECTION with Re-selection

### Setup (Create multiple test.py files)
```bash
mkdir -p ~/Desktop/projects/app1
mkdir -p ~/Desktop/projects/app2
mkdir -p ~/Documents/code

echo "# App 1" > ~/Desktop/projects/app1/test.py
echo "# App 2" > ~/Desktop/projects/app2/test.py
echo "# Docs" > ~/Documents/code/test.py
```

### Command
```
open test.py
```

### Expected Behavior
1. âœ“ Shows:
   ```
   Multiple files found:
   
   1. ~/Desktop/projects/app1/test.py
   2. ~/Desktop/projects/app2/test.py
   3. ~/Documents/code/test.py
   
   Select file (1-3 or 0 to cancel):
   ```

2. Select `1`

3. âœ“ Shows:
   ```
   Selected: /Users/[user]/Desktop/projects/app1/test.py
   Is this correct? (y/n):
   ```

4. Enter `n`

5. âœ“ Shows file list AGAIN (loops back to step 1)

6. Select `2`

7. âœ“ Confirms again

8. Enter `y`

9. âœ“ Proceeds with opening file

### Verify
- Correct file opens after confirmation

---

## âœ… Test 8: TYPO CORRECTION

### Test Commands
```
hlep
```

### Expected Behavior
1. âœ“ Shows: `Did you mean 'help'? (y/n):`
2. âœ“ If `y`: Runs `help` command
3. âœ“ If `n`: Cancels

### Other Typos to Test
- `mve` â†’ suggests `move`
- `instal` â†’ suggests `install`
- `cpy` â†’ suggests `copy`
- `dlete` â†’ suggests `delete`

---

## âœ… Test 9: CONTEXT TRACKING

### Commands (Run in sequence)
```
create folder myproject
```

Then immediately:
```
put a file named main.py in it
```

### Expected Behavior
1. âœ“ First command creates `~/Desktop/myproject/`
2. âœ“ Second command detects "in it" reference
3. âœ“ Uses stored context: `self.last_created_folder`
4. âœ“ Creates file at `~/Desktop/myproject/main.py`

### Verify
```bash
ls ~/Desktop/myproject/main.py
# File should exist
```

---

## âœ… Test 10: AI QUERY ROUTING

### Prerequisites
- TinyLlama/llamafile must be installed
- Check with: `ls ~/.luciferai/bin/llamafile`

### Test A: Multi-word Question
```
what is python
```

### Expected Behavior
âœ“ Routes to AI (not treated as unknown command)
âœ“ Returns AI response about Python

### Test B: Single-word Question
```
explain
```

### Expected Behavior
âœ“ Routes to AI if available
âœ“ Returns response or asks for clarification

### Test C: Natural Language Command
```
show me what files are in my desktop
```

### Expected Behavior
âœ“ Parses as natural language
âœ“ Executes appropriate command (list ~/Desktop)

---

## âœ… Test 11: CLEAR, EXIT, MAINMENU

### CLEAR
```
clear
```
âœ“ Clears terminal screen

### EXIT
```
exit
```
âœ“ Shows: `Lucifer bids you farewell...`
âœ“ Exits program cleanly

### MAINMENU
```
mainmenu
```
âœ“ Returns to main LuciferAI menu
âœ“ Shows ASCII art and options

---

## ğŸ“Š Test Summary Checklist

Copy this and check off as you test:

```
â˜ delete command with trash confirmation
â˜ open command with app selection
â˜ daemon watch with top 3 suggestions (no autofix)
â˜ daemon watch with autofix enabled
â˜ fix command with consensus
â˜ Up/Down arrow history (120 commands)
â˜ History persists across restarts
â˜ Multi-file selection with re-selection loop
â˜ Typo correction prompts
â˜ Context tracking ("in it" references)
â˜ AI query routing (multi-word)
â˜ clear command
â˜ exit command
â˜ mainmenu command
```

---

## ğŸ› Known Issues from Automated Tests

From test run (78.9% pass rate):

1. **Folder creation path** - May need manual verification
2. **Memory command** - Check if returns proper output
3. **Models info** - Verify displays correctly

---

## ğŸ¯ Success Criteria

All tests should:
- âœ“ Respond appropriately to user input
- âœ“ Show clear prompts and confirmations
- âœ“ Handle y/n inputs correctly
- âœ“ Loop back when user says 'n' to confirmation
- âœ“ Display consensus fixes with white background
- âœ“ Persist command history across restarts
- âœ“ Route unrecognized commands to AI when available
